{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21Stonney/langchain-gemini-starter/blob/main/it_aiagtactdj_01_enus_03_asset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KZdg2a5zBqMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292703a1-5c0f-46fa-f142-5f72592c3f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/155.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#  Install required packages\n",
        "!pip install -qU langchain langchain-google-genai google-generativeai==0.8.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, platform\n",
        "from google.colab import userdata\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain + Gemini\n",
        "import langchain, langchain_core\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "M8yv_6ILBytu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Set your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")"
      ],
      "metadata": {
        "id": "zO5mtoihBzNU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommended for demos: fast & economical\n",
        "model_name = \"gemini-2.0-flash\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_name,\n",
        "    convert_system_message_to_human=True,  # smoother behavior with system prompts\n",
        "    temperature=0.7,\n",
        ")\n",
        "print(f\" Ready with model: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiINCe26CVp8",
        "outputId": "4fd81bbc-0a99-46e1-8caa-76600a1cd6f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ready with model: gemini-2.0-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple sequential chain (Ideas → Summary)"
      ],
      "metadata": {
        "id": "zI9cA6hIC6zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: generate ideas\n",
        "idea_prompt = PromptTemplate.from_template(\n",
        "    \"Generate 3 creative ideas about: {topic}. Return them as a numbered list.\"\n",
        ")\n",
        "\n",
        "# Step 2: summarize the ideas\n",
        "summary_prompt = PromptTemplate.from_template(\n",
        "    \"Summarize the ideas below in 2 friendly sentences for a beginner:\\n\\n{ideas}\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "7ciGGsY4Ct1i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain\n",
        "\n",
        "idea_chain = idea_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "Y1DuBEyTDE7p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compose a chain where the output of idea_chain is fed into the summary prompt\n",
        "sequential_chain = {\n",
        "    \"ideas\": idea_chain,\n",
        "    \"topic\": RunnablePassthrough()\n",
        "} | summary_prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "e8quJB7MDIxP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"using AI to improve school homework feedback\"\n",
        "Creative_ideas = idea_chain.invoke({\"topic\": topic})\n",
        "summary = sequential_chain.invoke({\"topic\": topic})"
      ],
      "metadata": {
        "id": "KUlWN9BjDU-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Topic:\", topic)\n",
        "print(\" Creative Ideas : \", Creative_ideas)\n",
        "print(\" Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnSZoIT7Df-4",
        "outputId": "2098111b-a231-4635-9fe5-26e1e7c857f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Topic: using AI to improve school homework feedback\n",
            " Creative Ideas :  Here are 3 creative ideas about using AI to improve school homework feedback:\n",
            "\n",
            "1.  **Personalized Feedback Narrative Generation with \"Character\" Tutoring:** Imagine an AI system that analyzes student homework and generates feedback in the form of a personalized story or narrative. Instead of just saying \"You need to elaborate on your thesis statement,\" the AI might present a scenario: \"Professor Owl, your AI tutor, has noticed a fascinating seed of an idea in your opening paragraph! However, it's a bit like a hidden acorn – it needs more sunlight (details and evidence) to grow into a strong, convincing tree. Let's explore how you can expand on this concept...\" This approach leverages different \"character\" tutors (e.g., a detective for persuasive writing, a builder for math problems) each with a unique voice and learning style to cater to individual student preferences. The AI would also track which character and narrative style resonate most with each student, further personalizing the learning experience and making feedback more engaging and memorable.\n",
            "\n",
            "2.  **AI-Powered \"Argumentation Reconstructor\" for Essay Feedback:** This AI tool wouldn't just identify errors in grammar and spelling, but would actively *reconstruct* the student's argument as it understands it. It would then present this reconstructed argument back to the student, highlighting potential weaknesses in logic, gaps in evidence, and alternative perspectives. For example, the AI might say: \"Based on your essay, I understand your argument to be: A -> B -> C. However, you haven't explicitly connected B and C. Are you assuming a link here? What evidence supports this connection?\" This approach goes beyond surface-level feedback and encourages students to think critically about the underlying structure and validity of their arguments. The AI could also generate counter-arguments or alternative perspectives to stimulate deeper thinking.\n",
            "\n",
            "3.  **Adaptive Difficulty Feedback with \"Gamified\" Revision Challenges:** Instead of providing the same level of feedback to all students, this AI system would adapt the difficulty of its feedback based on the student's current understanding. For example, if a student consistently struggles with identifying the main idea, the AI might start with very basic feedback like, \"The main idea is usually found in the introduction or conclusion. Can you identify it in your writing?\" As the student improves, the AI would provide more complex feedback, such as, \"While your main idea is present, it could be more directly linked to your supporting arguments. Consider revising it to create a stronger connection.\" This system would be integrated with a gamified platform that presents revision challenges tailored to the specific feedback. Completing these challenges would earn points and badges, making the revision process more engaging and rewarding. The AI would track progress and adjust the difficulty of the challenges accordingly, ensuring that students are constantly challenged but not overwhelmed.\n",
            " Summary:\n",
            " AI can help make homework feedback much more helpful! Instead of just getting a grade, AI could create personalized learning plans, act as a debate partner to challenge your ideas, and ask questions that help you reflect on your mistakes and learn from them.\n"
          ]
        }
      ]
    }
  ]
}